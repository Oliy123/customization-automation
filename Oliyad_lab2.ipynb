{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Class!\n"
     ]
    }
   ],
   "source": [
    "print('Hello Class!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2\n",
    "## Solving Problems with Python\n",
    "\n",
    "This lab is meant as a first step into the wonderful world of scripting. We're going to be focusing on solving problems using a fundamental element of flow control: the if/then statement.\n",
    "\n",
    "The second half of this lab and next week's class will go over iteration and flow control (loops, etc.), but for the first half, you just need to think about the statement like this: \"*If* something is true, *then* do something; *if not* do something else.\"\n",
    "\n",
    "The best way to understand that is with some hands on examples, so let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But, first some housekeeping.\n",
    "\n",
    "This lab should appear to you as a series of markdown and code boxes with which you can interact. **If** it appears as a statically rendered page (try clicking on a box), then you are not loading it within jupyter or arcgis. Let's talk about how you set up environments for a moment.\n",
    "\n",
    "\n",
    "## The following is how to set up your lab using anaconda. If you are using arcgis, please skip to the next section.\n",
    "I like to create a new environment for each lab. This keeps everything nice and tiday and makes sure that any conflicts between versions of libraries are handled 'automagically' (*usually*). But, I've also had students create a single environment for each class. Feel free to do either. For now, let's talk about how you create en environment.\n",
    "\n",
    "**I am assuming that you have anaconda installed and are able to get to the anaconda prompt**. If that is not the case, [go here and do so](https://www.anaconda.com/download/).\n",
    "\n",
    "With your prompt staring at you, you can create an environment like so:\n",
    "`conda create -n lab2 python=3.7`\n",
    "\n",
    "That tells conda to create an environment named (-n) lab2 and to install python version 3.7 with it. You could just as easily give it another name or a different version of python. Anaconda will go out and find all the packages necessary to do this and prompt you that you are sure you want to install them, you are. **Note: If you are using the ESRI python prompt, you may get an error if you try to use a version of python other than 3.8**\n",
    "\n",
    "Ok, now once that's completed, it's time to activate your environment. You do so like so:\n",
    "\n",
    "**In windows:** `conda activate lab2`\n",
    "\n",
    "**In mac/linux:** `source activate lab2`\n",
    "\n",
    "You should now have `(lab2)` to the left of your prompt. This means that you are in the environment you created. \n",
    "\n",
    "Now it's time to install the packages we'll need for this lab. In this case, we only need jupyter notebooks, so go ahead and type:\n",
    "`conda install jupyter`\n",
    "\n",
    "This tells Anaconda to go out and find all the packages needed to run jupyter notebooks. You'll be prompted that you want to install them, you'll say yes again.\n",
    "\n",
    "Once ***all that*** is done, type in `jupyter notebook` and a notebook application should launch in your web browser. At that point, simply navigate to this file and open it again. **Boom**, you're ready to go.\n",
    "\n",
    "#### This may seem like a lot, but with time it will become like second nature. I recommend taking some time now to play with Anaconda and Jupyter; they are both extremely useful tools that, along with github, will help you organize and create amazing scripts.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Here are the instructions if you are choosing to remain within Arcgis (and its version of anaconda and jupyter).\n",
    "\n",
    "ESRI, in their vast wisdom, both installs a version of anaconda to manage packages within Arcgis Pro's python environment(s) **and** now allows you to open notebooks directly within ArcGIS Pro.\n",
    "\n",
    "If you want to use the command prompt, look for what ESRI calls the \"Python Command Prompt\" in your Windows Menu. It will load into what amounts to an anaconda prompt, but places you in a default `(arcgispro-py3)` environment. This means that anything you install (unless you change environments) will be included in the environment used by Arcgis Pro. This has benefits and dangers! You can both extend the functionality of python with ArcGIS Pro *and* potentially install something that doesn't work with core features of ArcGIS Pro. Fun!\n",
    "\n",
    "Once you have the command prompt open, go to the directions above for anaconda. They are identical because... ESRI is just using a version of anaconda! Sneaky!\n",
    "\n",
    "If you prefer to stick entirely to the GUI (not recommended, but you should find the path for coding that works best for you), **pages 229 to 250** of your textbook cover this topic. You can also read the ESRI documentation [here](https://pro.arcgis.com/en/pro-app/latest/arcpy/get-started/pro-notebooks.htm). \n",
    "\n",
    "---\n",
    "\n",
    "#### Of course, I'll be showing you **all** methods in class, so pay attention, review the videos, and read the documentation! \n",
    "\n",
    "#### Finally, think about your workflow. How will you *pull* things down from our class repository and *push* them up when you are done. **Set up your workflow now!**\n",
    "\n",
    "# Still with me, great. Let's look at `if` statements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking your number...\n",
      "The number is large!\n"
     ]
    }
   ],
   "source": [
    "x = 20\n",
    "\n",
    "print(\"Checking your number...\")\n",
    "if x > 4:\n",
    "    print('The number is large!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, ok, ok.\n",
    "That's pretty simple. True, but throughout this course you're going to learn how to use *relatively* simple concepts to break apart *seemingly* difficult problems to save time and energy and to accomplish some really neat things.\n",
    "\n",
    "As you can see, the format for an if/then statement in python looks like:\n",
    "```python\n",
    "if [something]:\n",
    "    [do something]\n",
    "```\n",
    "This seems trivial, but it's actually fairly fundamental - `if` allows you to tell a script to evaluate `[something]` and to perform a task **conditional upon that evaluation**.\n",
    "\n",
    "Think about it for a moment: If a set of data isn't in one project, reproject it. If files aren't in a directory, go get them. Etc.\n",
    "\n",
    "### Of course, what if we want it to do something `else`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking your number...\n",
      "Not quite big enough, I'm afraid\n"
     ]
    }
   ],
   "source": [
    "x = 10\n",
    "\n",
    "print('Checking your number...')\n",
    "if x > 20:\n",
    "    print('What a big number!')\n",
    "else:\n",
    "    print(\"Not quite big enough, I'm afraid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple enough.\n",
    "\n",
    "Now, let's introduce `elif` which stands for \"else if...\"\n",
    "\n",
    "Basically, this allows you to chain a bunch of `if` statements together. Bearing in mind, **ONLY THE FIRST STATEMENT THAT EVALUATES TO TRUE WILL BE PERFORMED**.\n",
    "\n",
    "Let's look at this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking your number...\n",
      "Pretty big!\n"
     ]
    }
   ],
   "source": [
    "x = 16\n",
    "\n",
    "print('Checking your number...')\n",
    "if x > 20:\n",
    "    print('What a big number!')\n",
    "elif x > 15:\n",
    "    print('Pretty big!')\n",
    "elif x > 10:\n",
    "    print('This is a fine number')\n",
    "else:\n",
    "    print('This number is too small')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note how *only* the second elif was performed.\n",
    "\n",
    "In other words, even though x **is** greater than 10 as well, only the code after `x > 15` was performed.\n",
    "\n",
    "**This is important, so I'll say it again in big letters:**\n",
    "### Only the first statement that evaluates to true will be performed.\n",
    "\n",
    "And with that, we're ready to start our lab. *No, seriously,* this is about learning to break apart difficult problems using relatively simple computational tools. We're ready to start!\n",
    "\n",
    "### Finally, remember to review your readings for this week (found on Canvas). They cover all of this material directly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Can I sleep?\n",
    "\n",
    "In this fairly classic problem (so, *yes*, if you feel like it you can easily look up the answer), I'm going to give you three lists. Each list contains two values. The first value is whether it is a weekday or not. The second value is if I am on vacation or not. Your goal is to output whether or not I can sleep in.\n",
    "\n",
    "An example will help.\n",
    "\n",
    "`[True, False]` would mean that it is a weekday and I am not on vacation. **Uh oh, better get up!**\n",
    "\n",
    "`[False, False]` would mean I am not on vacation, but it also isn't a weekday. **Sleep in!**\n",
    "\n",
    "Now, of course, all of this is a bit contrived as with kids there is never any sleeping in, but it's an exercise in evaluating boolean logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uh oh, better get up!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = [False, True]\n",
    "y = [True, True] \n",
    "z = [True, False]\n",
    "\n",
    "def check_sleep(weekday, vacation):\n",
    "  \n",
    "  if weekday is True and vacation is False:\n",
    "    return 'Uh oh, better get up!'\n",
    "  elif weekday is False and vacation is False:\n",
    "    return 'Sleep in!'\n",
    "  elif weekday is True and vacation is True:\n",
    "    return 'Sleep in!'  \n",
    "  else:\n",
    "    return 'Uh oh, better get up!'\n",
    "\n",
    "print(check_sleep(True, False))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Odd addition.\n",
    "\n",
    "Another classic with a twist. Here, I'm going to give you three lists of two numbers. What I want you to do is write a script that checks each pair of numbers and *if both numbers are odd* multiplies them and prints the result. Otherwise, it prints the result of adding both numbers.\n",
    "\n",
    "Example: `[3, 5]` would return `15`.\n",
    "\n",
    "While: `[3, 6]`would return `9`.\n",
    "\n",
    "Hint: Look up the modulo operator in python (it's in your lecture as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    }
   ],
   "source": [
    " \n",
    "a = [7, 9] \n",
    "b = [10, 3] \n",
    "c = [2, 5] \n",
    "def check_num(x,y):\n",
    "    if (x % 2) == 0 and (y % 2) == 0:\n",
    "        return (x+y)\n",
    "    else:\n",
    "         return (x*y)\n",
    "\n",
    "print(check_num(5,6))\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Twenty One.\n",
    "\n",
    "Here's a nice relaxing final problem.\n",
    "I'll give you two numbers, return `True` if they add up to 21, return `False` if they don't; however, if the numbers are identical, return the string \"Split\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split\n"
     ]
    }
   ],
   "source": [
    "p = [19, 2]\n",
    "q = [7, 7]\n",
    "r = [4, 6]\n",
    "\n",
    "def check_num(x, y):\n",
    "    if  x==y:\n",
    "        return 'split'\n",
    "    elif (x + y) == 21:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "print(check_num(7, 7))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Is it even?\n",
    "\n",
    "Write a script that asks the user for a number and then prints out whether the number is even or not. Hint: Think about if/then statements and how you check for the remainder of a something.\n",
    "\n",
    "Note: For this problem, assume that the user inputs an actual number.\n",
    "\n",
    "**Bonus Possible:** Don't assume your user gives a valid input. Instead, build some form of error catching that continues to ask for an input *until* the user gives a number. **+1 pt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Even number: fd\n",
      "Sorry, I didn't understand that.\n",
      "Enter Even number: \n",
      "Sorry, I didn't understand that.\n",
      "Enter Even number: 3\n",
      "3 is Odd\n",
      "Enter Even number: er\n",
      "Sorry, I didn't understand that.\n",
      "Enter Even number: 4\n",
      "4 is Even\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    try:\n",
    "        num = int(input(\"Enter Even number: \"))\n",
    "    except ValueError:\n",
    "        print(\"Sorry, I didn't understand that.\")\n",
    "        continue\n",
    "    if (num%2) != 0:\n",
    "        print(\"{0} is Odd\".format(num))\n",
    "    elif (num%2) == 0:\n",
    "        print(\"{0} is Even\".format(num))\n",
    "        break\n",
    "    \n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Problem 1: Find the square root (+2 pts possible)\n",
    "\n",
    "Write a script that asks the user to input a number and then finds the square root of said number within .001. You may assume that the input is a valid number; however, you may not use the built in commands to find square roots (such as sqrt()) or x**(1/2)). **Instead, you must use only multiplication, division, addition, and subtraction (you may also use absolute value)**.\n",
    "\n",
    "Pay attention to how many iterations your solution takes. There is an optimal solution here; however, don't look it up, instead spend some time thinking about how you might 'guess' a number. Use nested loops if you need to. Partial credit is not possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter a number: 5\n",
      "square root: 2.23606797749979\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint 1\n",
    "#### You should have up until this point completed by the start of the second class (1/21/21). It's ok if some things aren't quite working yet, but you really should be to this point if at all possible. \n",
    "#### You will receive 2 points (out of a total of 15 for the lab) for being at this checkpoint.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1 - Week 2\n",
    "## Iteration, data parsing, and the like\n",
    "\n",
    "This week, we're not yet focusing on spatial data (or arcgis) quite yet, but instead really diving into some of the core concepts with coding and automation - namely the ability to parse and manipulate data through iteration and flow control.\n",
    "\n",
    "As always, spend some time reading through the lab and thinking about how to break apart each 'chunk' of the problem into something small. Some of these problems will have immediate applied uses, while others will simply be asking you to think computationally – about what you can and cannot solve using Python and how it might be used in a variety of generalized tasks. You will also gain familiarity with the specific syntax of the Python language.\n",
    "\n",
    "There are a wide variety of articles, guides, tutorials, and reference materials available on the Python language. You’re encouraged to read through many of these and refer to them when you run into difficulty. Make sure you understand why any solution works or you will run into significant difficulties later. **But, never forget your assigned readings and lectures. They will be extremely useful as references**.\n",
    "\n",
    "As always, you'll turn your lab in [here](https://github.com/UWTMGIS/TGIS501_w21_Students/tree/master/lab2). File format remains `[lastname]_lab2.ipynb`\n",
    "\n",
    "### Ready, then let's goooooo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Is GIS really *the best*?\n",
    "\n",
    "### Part 1\n",
    "In the files repository, you'll find a file called `GIS_is_the_best.txt`. You're going to open that file and count the **total** number of words in it.\n",
    "\n",
    "There are a few approaches to this. You can load the file directly from the web (which we'll cover in a later lab, but if you feel like diving in, check out this [stack overflow discussion](https://stackoverflow.com/questions/1393324/in-python-given-a-url-to-a-text-file-what-is-the-simplest-way-to-read-the-cont) or [this module](http://docs.python-requests.org/en/master/). I find the latter easier to work with, but your mileage may vary). **Alternatively**, simply move the file to a local directory and open it like so:\n",
    "\n",
    "```python\n",
    "with open('file location', 'r') as file:\n",
    "    #do some stuff\n",
    "```\n",
    "\n",
    "Then, you need to count the total number of words used.\n",
    "A few hints for this:\n",
    "1. Here's a nice [tutorial](https://www.pythonforbeginners.com/files/reading-and-writing-files-in-python) on dealing with text files.\n",
    "2. Remember list comprehension (**check your readings!**): how are you going to count words?\n",
    "3. the .upper(), .lower(), and .split() methods all might be useful.\n",
    "\n",
    "#### In summary, your next cell should load up the text file and print out the total number of words in it (it should be 28,177)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in text file : 28177\n"
     ]
    }
   ],
   "source": [
    "#From a tutorial website  https://pythonguides.com/python-count-words-in-file/, I learned how to count a text.\n",
    "\n",
    "file = open(r\"C:\\Users\\oliya\\Documents\\TGIS501_w22_Files-main\\GIS_is_the_best.txt\", \"rt\")\n",
    "data = file.read()\n",
    "words = data.split()\n",
    "\n",
    "print('Number of words in text file :', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2\n",
    "Now it's time to find out what the most common word in that file is. This is a fairly fundamental task of parsing data, so it's good practice (also, I'll ask you to do it again in a slightly more complicated way below).\n",
    "\n",
    "Open the file again and, this time, return the two most common words and how many times they have been used.\n",
    "\n",
    "There's one additional thing to note: capitalization doesn't matter. So, GIS, gis, and Gis should all be counted the same. Similarly, Geospatial and geospatial would be the same. Here, the .upper() or .lower() method can help you.\n",
    "\n",
    "In summary, your next cell should output the two most common words in the text file and how many times it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "information 7545\n",
      "geographic 7545\n"
     ]
    }
   ],
   "source": [
    "words = open(r'C:\\Users\\oliya\\Documents\\TGIS501_w22_Files-main\\GIS_is_the_best.txt').read().lower().split()\n",
    "\n",
    "# Get the set of unique words.\n",
    "uniques = []\n",
    "for word in words:\n",
    "  if word not in uniques:\n",
    "    uniques.append(word)\n",
    "\n",
    "# Make a list of (count, unique) tuples.\n",
    "counts = []\n",
    "for unique in uniques:\n",
    "  count = 0              # Initialize the count to zero.\n",
    "  for word in words:     # Iterate over the words.\n",
    "    if word == unique:   # Is this word equal to the current unique?\n",
    "      count += 1         # If so, increment the count\n",
    "  counts.append((count, unique))\n",
    "\n",
    "counts.sort()            # Sorting the list puts the lowest counts first.\n",
    "counts.reverse()         # Reverse it, putting the highest counts first.\n",
    "# Print the two words with the highest counts.\n",
    "for i in range(min(2, len(counts))):\n",
    "  count, word = counts[i]\n",
    "  print('%s %d' % (word, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: A 'love' of Lovecraft\n",
    "\n",
    "Ok, first, let's get it out of the way: H.P. Lovecraft was a disgusting racist. We're using this text because it's in the public domain and uses a lot of unique words, but let's not take our eyes off the prize; this is not an endorsement of the author.\n",
    "\n",
    "With that out of the way, you'll find a .txt copy of *The Shunned House* in the same files repository where you found this lab. Just like before, you can pull the files down locally or (try to) access them through the web (which will be covered in detail in a later lab).\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Here, I want you to count the **number of unique words** in the text. \n",
    "A few directions:\n",
    "1. Case **does not** matter - so 'Whisker' should be the same as 'whisker.'\n",
    "2. Make sure you strip out punctuation - otherwise 'whisker?' and 'whisker!' will come back as different words.\n",
    "3. Plurals are different words in this exercise - 'whiskers' and 'whisker' count separately.\n",
    "\n",
    "A few hints:\n",
    "1. Check out the [collections](https://docs.python.org/2/library/collections.html#collections) module.\n",
    "2. One way to do this would be to create a dictionary of each word and then check the dictionaries length.\n",
    "3. You should get around 3,000 words depending on what assumptions you bake into this. There's no austere 'right' answer as the directions are a bit opaque intentionally (design decisions matter!).\n",
    "4. If you want to get *real* fancy, students in the past have made use of NLTK to do this. If that seems overwhelming, *don't worry!* Remember, different people will have different familiarities with python. Right now, **you have all the tools you need to do this**, there's just always 'more' possible!\n",
    "\n",
    "#### In summary, your next cell should output how many unique words Lovecraft uses in the copy of the Shunned House I have provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Unique Words: 3675\n"
     ]
    }
   ],
   "source": [
    "count = 0                     #the counter with default value set to zero.\n",
    "file = open(r\"C:\\Users\\oliya\\Documents\\TGIS501_w22_Files-main/shunned_house.txt\", \"r\")  #opening a text file in a read-only mode\n",
    "read_data = file.read()       #reading the data stored in a file\n",
    "words = set(read_data.split())#split the data () and also we have removed the duplicate values\n",
    "for word in words:            #started a for loop on total words and each time the loop runs it adds one to the counter   \n",
    "    count += 1\n",
    "    \n",
    "print('Total Unique Words:', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2\n",
    "\n",
    "Excluding prepositions ('from,' 'the,' 'an', 'with', 'a', etc.) what are the five most frequently used words in *The Shunned House* and how many times does each appear?\n",
    "\n",
    "#### In summary, your next cell should output the five most common non-prepositions in the text provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('i', 189), ('was', 154), ('that', 135), ('had', 133), ('it', 123)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "file = open(r\"C:\\Users\\oliya\\Documents\\TGIS501_w22_Files-main\\shunned_house.txt\", \"r\").read().lower().replace(\"the\", \" \").replace(\",\", \" \").replace(\"and\", \" \").replace(\"of\", \" \").replace(\".\", \" \").replace(\" \", \" \").replace(\" to \", \" \").replace(\" in \", \" \").replace(\"g\", \" \").replace(\"in\", \" \").replace(\" a \", \" \")\n",
    "\n",
    "allWords = word_tokenize(file)\n",
    "allWordDist = nltk.FreqDist(w.lower() for w in allWords)    \n",
    "mostCommon= allWordDist.most_common(5)\n",
    "print(mostCommon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "Ok, last Lovecraft; I promise.\n",
    "\n",
    "Last time, we counted the words he loved to use and how he used them. But, Lovecraft is also known for his lugubrious sentences, the long-winding means by which he tells us his terrible tales. I’m interested in how many characters his average sentence is. I’d also like a printed copy of the longest sentence and the shortest sentence in The Shunned House.\n",
    "\n",
    "Think about how you opened the file, read it, and parsed it into a list last time… *What means do you have to count the character length of objects? What format do those objects have to be?* Etc.\n",
    "\n",
    "This question will help you think about ways to parse through and iterate over different types of data sets (in this case a text file).\n",
    "\n",
    "Hint: In the past, some students have used [nltk](https://pythonspot.com/category/nltk/) to solve this problem; **it is not necessary**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest sentence use: 912 characters.\n",
      "A weak, \n",
      "filtered glow from the rain-harassed street-lamps outside, and a feeble \n",
      "phosphorescence from the detestable fungi within, showed the dripping \n",
      "stone of the walls, from which all traces of whitewash had vanished; \n",
      "the dank, fetid and mildew-tainted hard earth floor with its obscene \n",
      "fungi; the rotting remains of what had been stools, chairs, and tables, \n",
      "and other more shapeless furniture; the heavy planks and massive beams \n",
      "of the ground floor overhead; the decrepit plank door leading to bins \n",
      "and chambers beneath other parts of the house; the crumbling stone \n",
      "staircase with ruined wooden hand-rail; and the crude and cavernous \n",
      "fireplace of blackened brick where rusted iron fragments revealed the \n",
      "past presence of hooks, andirons, spit, crane, and a door to the Dutch \n",
      "oven--these things, and our austere cot and camp chairs, and the heavy \n",
      "and intricate destructive machinery we had brought.\n",
      " The shortest sentence use: 20 characters.\n",
      "The horror has gone.\n",
      "Average character is: 466.0\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "file = open(r\"C:\\Users\\oliya\\Documents\\TGIS501_w22_Files-main\\shunned_house.txt\", \"r\")\n",
    "read_data = file.read()\n",
    "nltk.tokenize.sent_tokenize(read_data)\n",
    "\n",
    "# split text into sentences\n",
    "tokenized_sentences = nltk.tokenize.sent_tokenize(read_data)\n",
    "\n",
    "# get longest sentence and its length\n",
    "longest_sen = max(tokenized_sentences, key=len)\n",
    "longest_sen_len = len(longest_sen)\n",
    "\n",
    "# get shortest word and its length\n",
    "shortest_sen = min(tokenized_sentences, key=len)\n",
    "shortest_sen_len = len(shortest_sen)\n",
    "# get average sentence length\n",
    "\n",
    "\n",
    "average_sentence_length = (len(longest_sen) + len(shortest_sen))/2\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "print ('The longest sentence use:',longest_sen_len,'characters.', )\n",
    "print (longest_sen)\n",
    "print (' The shortest sentence use:',shortest_sen_len,'characters.',)\n",
    "print (shortest_sen)\n",
    "print ('Average character is:', average_sentence_length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus Problem 2: Vowel Squares (+2 pts possible)\n",
    "This is a bit of a 'classic' problem. I'm going to give you a two-dimensional matrix of letters. You need to analyze said matrix to see if within it there exists a 2 by 2 grid of all vowels (hint: there is). If so, you print out the members of that grid; if not, you print out \"No match found.\"\n",
    "\n",
    "In other words, I'm going to give you something like this:\n",
    "\n",
    "a b c d e f\n",
    "\n",
    "g h i j k l\n",
    "\n",
    "**a a** k e v o\n",
    "\n",
    "**i o** e r p z\n",
    "\n",
    "And, you'd need to return a a i o.\n",
    "\n",
    "**THIS IS HARD**. Work together! Don't look up a solution, do think about how you might parse through this. There are many solutions, one I might consider is creating a new matrix that simple records if something is a vowel or not (i.e. a 1 value for a vowel, a 0 for not, etc.). *Partial credit is possible*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "letters = [['a', 'j', 'k', 'e', 'i'], ['b', 'o', 'e', 'n', 'a'], ['u', 'i', 'a', 'z', 'i'] ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# No-credit, fun times\n",
    "## Want to build a chatbot?\n",
    "\n",
    "This isn't really related to anything we're doing in class per se, but it's a fun example of how powerful libraries can be in python.\n",
    "\n",
    "In this case, I'm going show you how to use the library [markovify](https://github.com/jsvine/markovify) to generate 10 short sentences from any lengthy piece of text you want to (I'm always partial to Capital Vol 1, but you can use the Lovecraft selection you already have, or anything you want - it just has to be pretty long). I'll be using the Lovecraft here, just because it's on hand and you'll be able to follow note for note.\n",
    "\n",
    "Markovify has directions at the link above which are pretty straightforward. But, I'll also give you example code below. Poke at it, change some things up! Did you know you can combine texts (and even weight them differently) to produce different 'voices.' This is an incredibly simple model, but it's a lot of fun. If you'd like to see where the state of the art is right now, check out [GPT-3](https://github.com/openai/gpt-3) or the API for it [here](https://openai.com/blog/openai-api/)).\n",
    "\n",
    "Once you get the hang of it (changing texts, sentence length, etc.), go look at the documentation linked above. You'll find lots of ways to tweak the output - from changing the depth of the search (roughly how many words must be strung together in the model) to weighting different texts differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "The next step, for example, might be to set up a listener to a twitter account that monitors for either someone mentioning the author or someone tweeting at the account or... whatever. Then your little bot could respond. We'll get to how you might do that later in the course, for now, just have some fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
